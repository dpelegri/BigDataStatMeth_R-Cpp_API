# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Compute Cholesky decomposition with hdf5 data files
#'
#' Compute cholesky decomposition with datasets stored in hdf5 data files. Function returns the upper triangular matrix.
#'
#' @param filename, character array with the name of an existin hdf5 data file containing the dataset to be modified
#' @param group, character array indicating the input group where the data set to be modified. 
#' @param dataset, character array indicating the input dataset to be modified
#' @param outdataset character array with output dataset name where we want to store results
#' @param outgroup optional, character array with output group name where we want to 
#' store results if not provided then results are stored in the same group as original dataset
#' @param fullMatrix boolean, optional parameter, by default false. 
#' If fullMatrix = true, in the hdf5 file the complete matrix is stored. 
#' If false, only the lower triangular matrix is saved
#' @param force, optional boolean if true, previous results in same location inside 
#' hdf5 will be overwritten, by default force = false, data was not overwritten.
#' @param threads optional parameter. Integer with numbers of threads to be used
#' @param elementsBlock, optional integer defines de maximum number of elements 
#' to read from hdf5 data file in each block. By default this value is set 
#' to 10000. If matrix is bigger thant 5000x5000 then block is set to number 
#' of rows or columns x 2
#' @return Original hdf5 data file with Cholesky decomposition
#' @examples
#' 
#' library(BigDataStatMeth)
#' library(rhdf5)
#' 
#' set.seed(1234)
#'     Y <- matrix(sample.int(10, 100, replace = TRUE), ncol = 10)
#'     
#' # devtools::reload(pkgload::inst("BigDataStatMeth"))
#' Ycp <- crossprod(Y)
#'         
#' # devtools::reload(pkgload::inst("BigDataStatMeth"))
#' bdCreate_hdf5_matrix(filename = "test_temp.hdf5", 
#'                         object = Ycp, group = "data", dataset = "matrix",
#'                         transp = FALSE,
#'                         overwriteFile = TRUE, overwriteDataset = TRUE, 
#'                         unlimited = FALSE)
#'        
#' # Get Inverse Cholesky
#' bdCholesky_hdf5(filename = "test_temp.hdf5", group = "data", 
#'    dataset = "matrix", outdataset = "matrixDec", outgroup = "Cholesky_Dec", 
#'    fullMatrix = FALSE, force = TRUE)
#'        
#' res <-  h5read("test_temp.hdf5", "Cholesky_Dec/matrixDec")
#' 
#' @export
bdCholesky_hdf5 <- function(filename, group, dataset, outdataset, outgroup = NULL, fullMatrix = NULL, force = NULL, threads = NULL, elementsBlock = 1000000L) {
    invisible(.Call('_BigDataStatMeth_bdCholesky_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outdataset, outgroup, fullMatrix, force, threads, elementsBlock))
}

#' Compute inverse cholesky with hdf5 data files
#'
#' Compute inverse cholesky with datasets stored in hdf5 data files
#'
#' @param filename, character array with the name of an existin hdf5 data file containing the dataset to be modified
#' @param group, character array indicating the input group where the data set to be modified. 
#' @param dataset, character array indicating the input dataset to be modified
#' @param outdataset character array with output dataset name where we want to store results
#' @param outgroup optional, character array with output group name where we want to 
#' store results if not provided then results are stored in the same group as original dataset
#' @param fullMatrix boolean, optional parameter, by default false. 
#' If fullMatrix = true, in the hdf5 file the complete matrix is stored. 
#' If false, only the lower triangular matrix is saved
#' @param force, optional boolean if true, previous results in same location inside 
#' hdf5 will be overwritten, by default force = false, data was not overwritten.
#' @param threads optional parameter. Integer with numbers of threads to be used
#' @param elementsBlock, optional integer defines de maximum number of elements 
#' to read from hdf5 data file in each block. By default this value is set 
#' to 10000. If matrix is bigger thant 5000x5000 then block is set to number 
#' of rows or columns x 2
#' @return Original hdf5 data file with Inverse of Cholesky
#' @examples
#' 
#' library(BigDataStatMeth)
#' library(rhdf5)
#' 
#' set.seed(1234)
#'     Y <- matrix(sample.int(10, 100, replace = TRUE), ncol = 10)
#'     
#' # devtools::reload(pkgload::inst("BigDataStatMeth"))
#' Ycp <- crossprod(Y)
#'         
#' # devtools::reload(pkgload::inst("BigDataStatMeth"))
#' bdCreate_hdf5_matrix(filename = "test_temp.hdf5", 
#'                         object = Ycp, group = "data", dataset = "matrix",
#'                         transp = FALSE,
#'                         overwriteFile = TRUE, overwriteDataset = TRUE, 
#'                         unlimited = FALSE)
#'        
#' # Get Inverse Cholesky
#'        res <- bdInvCholesky_hdf5(filename = "test_temp.hdf5", group = "data", 
#'        dataset = "matrix", outdataset = "invmatrix", outgroup = "InvCholesky", 
#'        fullMatrix = FALSE, force = TRUE)
#' 
#' @export
bdInvCholesky_hdf5 <- function(filename, group, dataset, outdataset, outgroup = NULL, fullMatrix = NULL, force = NULL, threads = 2L, elementsBlock = 1000000L) {
    invisible(.Call('_BigDataStatMeth_bdInvCholesky_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outdataset, outgroup, fullMatrix, force, threads, elementsBlock))
}

#' QR Decomposition 
#' 
#' This function compute QR decomposition (also called a QR factorization) 
#' of a matrix \code{A} into a product \code{A = QR} of an 
#' orthogonal matrix Q and an upper triangular matrix R.
#' 
#' @param X a real square matrix 
#' @param thin boolean, (optional) if thin = true returns Q thin decomposition else 
#' returns Q full decomposition, default is thin = false
#' @param block_size (optional) block size to perform computation
#' @param threads (optional) number of concurrent threads in parallelization if threads is null then threads =  maximum number of threads available
#' @return List with orthogonal matrix \code{Q} and upper triangular matrix \code{R} 
#' @export
bdQR <- function(X, thin = NULL, block_size = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdQR', PACKAGE = 'BigDataStatMeth', X, thin, block_size, threads)
}

#' QR Decomposition hdf5
#' 
#' This function compute QR decomposition \(also called a QR factorization\) 
#' of a matrix \code{A} into a product \code{A = QR} of an 
#' orthogonal matrix Q and an upper triangular matrix R.
#' @param filename, character array with the name of an existin hdf5 data file 
#' containing the dataset to be modified
#' @param group, character array indicating the input group where the data set 
#' to be modified. 
#' @param dataset, character array indicating the input dataset to be modified
#' @param outgroup optional, character array with output group name where we want to 
#' store results if not provided then results are stored in the same group as 
#' original dataset
#' @param outdataset character array with output dataset name where we want to 
#' store results, results are stored as Q.\<outdataset\> and R.\<outdataset\>
#' @param thin boolean, if thin = true returns Q thin decomposition else 
#' returns Q full decomposition, default is thin = false
#' @param block_size \(optional\) block size to perform computation
#' @param overwrite boolean\(optional\) if overwrite = TRUE, if exis 
#' @param threads \(optional\) number of concurrent threads in parallelization if 
#' threads is null then threads =  maximum number of threads available
#' @return List with orthogonal matrix \code{Q}  and upper triangular matrix \code{R}
#' @export
bdQR_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, thin = NULL, block_size = NULL, overwrite = NULL, threads = NULL) {
    invisible(.Call('_BigDataStatMeth_bdQR_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, thin, block_size, overwrite, threads))
}

#' Block SVD decomposition for hdf5 files using an incremental algorithm.
#'
#' Singular values and left singular vectors of a real nxp matrix 
#' Block SVD decomposition using an incremental algorithm.
#' @param file a real nxp matrix in hdf5 file
#' @param group group in hdf5 data file where dataset is located
#' @param dataset matrix dataset with data to perform SVD
#' @param k number of local SVDs to concatenate at each level 
#' @param q number of levels
#' @param bcenter (optional, defalut = TRUE) . If center is TRUE then centering 
#' is done by subtracting the column means (omitting NAs) of x from their 
#' corresponding columns, and if center is FALSE, no centering is done.
#' @param bscale (optional, defalut = TRUE) .  If scale is TRUE then scaling is 
#' done by dividing the (centered) columns of x by their standard deviations if 
#' center is TRUE, and the root mean square otherwise. If scale is FALSE, no 
#' scaling is done.
#' @param rankthreshold double, threshold used to determine the range of the array. 
#' The matrix rank is equal to the number of singular values different from the 
#' threshold. By default, threshold = 0 is used to get the matrix rank , but it 
#' can be changed to an approximation of 0.
#' @param method optional, defalut is "auto" possible values are: "auto", 
#' "blocks", "full":
#'     * `"auto"`:
#'       The option method = "auto" chooses the "full" or 
#'       "blocks" method depending on the size of the matrix to be decomposed 
#'     * `"blocks"`:
#'       The SVD decomposition can be carried out by blocks, recommended option 
#'       for large matrices that do not fit in memory
#'     * `"full"`:
#'       The SVD decomposition is performed directly without partitioning the matrix
#' 
#' @param threads (optional) only used in some operations inside function. If 
#' threads is null then threads =  maximum number of threads available - 1.
#' @return a list of three components with the singular values and left and 
#' right singular vectors of the matrix
#' @return A List with : 
#' 
#'   * `"u"`:
#'     eigenvectors of AA^t, mxn and column orthogonal matrix 
#'   * `"v`:
#'     eigenvectors of A^tA, nxn orthogonal matrix
#'   * `"d"`:
#'     singular values, nxn diagonal matrix (non-negative real values) 
#' 
#' @export
bdSVD_hdf5 <- function(file, group = NULL, dataset = NULL, k = 2L, q = 1L, bcenter = TRUE, bscale = TRUE, rankthreshold = 0.0, force = NULL, method = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdSVD_hdf5', PACKAGE = 'BigDataStatMeth', file, group, dataset, k, q, bcenter, bscale, rankthreshold, force, method, threads)
}

#' Solve matrix equations
#' 
#' This function solve matrix equations 
#'  \code{A * X = B } 
#' where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
#' 
#' @param A numerical matrix. 
#' @param B numerical matrix.
#' @return X numerical matrix. 
#' @examples
#' 
#' library(BigDataStatMeth)
#' 
#' n <- 500
#' m <- 500
#' 
#' # R Object
#' 
#' A <- matrix(runif(n*m), nrow = n, ncol = m)
#' B <- matrix(runif(n), nrow = n)
#' AS <- A%*%t(A)
#'       
#' X <- bdSolve(A, B)
#' XR <- solve(A,B)
#'       
#' all.equal(X, XR, check.attributes=FALSE)
#'   
#' @export
bdSolve <- function(A, B) {
    .Call('_BigDataStatMeth_bdSolve', PACKAGE = 'BigDataStatMeth', A, B)
}

#' Solve matrix equations
#' 
#' This function solve matrix equations 
#'  \code{A * X = B } 
#' where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
#' 
#' @param A numerical matrix. 
#' @param B numerical matrix.
#' @return X numerical matrix. 
#' @examples
#' 
#' library(BigDataStatMeth)
#' 
#' n <- 500
#' m <- 500
#' 
#' # R Object
#' 
#' A <- matrix(runif(n*m), nrow = n, ncol = m)
#' B <- matrix(runif(n), nrow = n)
#' AS <- A%*%t(A)
#'       
#' X <- bdSolve(A, B)
#' XR <- solve(A,B)
#'       
#' all.equal(X, XR, check.attributes=FALSE)
#'   
#' @export
bdSolve_hdf5 <- function(filename, groupA, datasetA, groupB, datasetB, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdSolve_hdf5', PACKAGE = 'BigDataStatMeth', filename, groupA, datasetA, groupB, datasetB, outgroup, outdataset, overwrite))
}

#' Apply function to different datasets inside a group
#'
#' Apply function to different datasets inside a group
#' 
#' @param filename, Character array, indicating the name of the file to create
#' @param group, Character array, indicating the input group where the data set
#' to be imputed is. 
#' @param datasets, Character array, indicating the input datasets to be used
#' @param outgroup, Character, array, indicating group where the data set will 
#' be saved after imputation if `outgroup` is NULL, output dataset is stored 
#' in the same input group. 
#' @param func, Character array, function to be applyed : 
#' QR to apply bdQR() function to datasets
#' CrossProd to apply bdCrossprod() function to datasets
#' tCrossProd to apply bdtCrossprod() function to datasets
#' invChol to apply bdInvCholesky() function to datasets
#' blockmult to apply matrix multiplication, in that case, we need the datasets 
#' to be used defined in b_datasets variable, datasets and b_datasets must be 
#' of the same lenght, in that case, the operation is performed according to 
#' index, for example, if we have `datasets = \{"A1", "A2", "A3\}` and 
#' `b_datasets = \{"B1", "B2", "B3\}`, the functions performs : A1%*%B1, 
#' A2%*%B2 and A3%*%B3 
#' CrossProd_double to  performs crossprod using two matrices, see blockmult 
#' tCrossProd_double to  performs transposed crossprod using two matrices, 
#' see blockmult 
#' solve to solve matrix equation system, see blockmult for parametrization 
#' sdmean to get sd and mean from de datasets by cols or rows
#' @param b_group, optional Character array indicating the input group where 
#' data are stored when we need a second dataset to operate, for example in 
#' functions like matrix multiplication
#' @param b_datasets, optional Character array indicating the input datasets 
#' to be used when we need a second dataset in functions like matrix 
#' multiplication
#' @param force, optional Boolean if true, previous results in same location 
#' inside hdf5 will be overwritten, by default force = false, data was not 
#' overwritten.
#' @param transp_dataset optional parameter. Boolean if true we use the 
#' transposed dataframe to perform calculus. By default transp_dataset = false, 
#' we use the original dataset stored in hdf5 data file. Currently this option 
#' is only valid with "blockmult", "CrossProd_double" and "tCrossProd_double"
#' @param transp_bdataset optional parameter. Boolean if true we use the 
#' transposed dataframe to perform calculus.By default transp_bdataset = false, 
#' we use the original dataset stored in hdf5 data file. Currently this option 
#' is only valid with "blockmult", "CrossProd_double" and "tCrossProd_double"
#' @param fullMatrix boolean, optional parameter used in Inverse Cholesky, by 
#' default false. If fullMatrix = true, in the hdf5 file the complete matrix 
#' is stored. If false, only the lower triangular matrix is stored
#' @param byrows boolean, optional parameter used in sd and mean calculus, by 
#' default false. If byrows = true, the sd and mean is computed by columns. 
#' If false, sd and mean is computed by rows.
#' @param threads optional parameter. Integer with numbers of threads to be used
#' @return Original hdf5 data file with results after apply function to 
#' different datasets
#' @export
bdapply_Function_hdf5 <- function(filename, group, datasets, outgroup, func, b_group = NULL, b_datasets = NULL, force = FALSE, transp_dataset = FALSE, transp_bdataset = FALSE, fullMatrix = FALSE, byrows = FALSE, threads = 2L) {
    invisible(.Call('_BigDataStatMeth_bdapply_Function_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, datasets, outgroup, func, b_group, b_datasets, force, transp_dataset, transp_bdataset, fullMatrix, byrows, threads))
}

#' PCA Descomposition
#' 
#' Compute PCA
#' 
#' @param filename string, file name where dataset is stored 
#' @param group string group name  where dataset is stored in file
#' @param dataset string dataset name with data to perform PCA
#' @param ncomponents integer, number of components to be computed, by default 
#' ncomponents = 0, all components are computed
#' @param bcenter logical value if true data is centered to zero
#' @param bscale logical value, if true data is scaled
#' @param k number of local SVDs to concatenate at each level, performance parameter 
#' @param q number of levels to compute SVD for PCA, performance parameter
#' @param rankthreshold double, threshold used to determine the range of the array. 
#' The matrix rank is equal to the number of
#' singular values different from the threshold. By default, threshold = 0 is used 
#' to get the matrix rank , but it can be changed to an approximation of 0.
#' @param SVDgroup string. Name of the group where the SVD results are located. 
#' If it has been previously calculated. This group must contain the d, u and v datasets.
#' @param force logical value, if true, the SVD is forced to be computed although 
#' the SVD exists. 
#' @param method optional, defalut = "auto" possible values are: "auto", 
#' "blocks", "full":
#' 
#'   * `"auto"`:
#'     The option method = "auto" chooses the "full" or "blocks" method depending on 
#'     the size of the matrix to be decomposed
#'   * `"blocks"`:
#'     The PCA can be carried out by blocks, recommended option for large matrices 
#'     that do not fit in memory
#'   * `"full"`:
#'     The PCA is performed directly without partitioning the matrix 
#' 
#' @param threads integer number of threads used to run PCA
#' @return original file with results in folder PCA/\<datasetname\>
#' @export
bdPCA_hdf5 <- function(filename, group, dataset, ncomponents = 0L, bcenter = FALSE, bscale = FALSE, k = 2L, q = 1L, rankthreshold = 0.0, SVDgroup = NULL, overwrite = FALSE, method = NULL, threads = NULL) {
    invisible(.Call('_BigDataStatMeth_bdPCA_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, ncomponents, bcenter, bscale, k, q, rankthreshold, SVDgroup, overwrite, method, threads))
}

#' Bind matrices by rows or columns
#'
#' Merge existing matrices inside hdf5 data file by rows or by columns
#' 
#' @param filename, character array indicating the name of the file to create
#' @param group, character array indicating the input group where the data set to be imputed is. 
#' @param datasets, character array indicating the input dataset to be imputed
#' @param outgroup, character array indicating group where the data set will be saved after imputation if `outgroup` is NULL, output dataset is stored in the same input group. 
#' @param outdataset, character array indicating the name for the new merged dataset
#' @param func, character array function to be applyed
#' \describe{
#'     \item{bindRows}{merge datasets by rows}
#'     \item{bindCols}{merge datasets by columns}
#' }
#' @param overwrite, boolean if true, previous results in same location inside hdf5 will be overwritten.
#' @return Original hdf5 data file with results after input datasets
#' @export
bdBind_hdf5_datasets <- function(filename, group, datasets, outgroup, outdataset, func, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdBind_hdf5_datasets', PACKAGE = 'BigDataStatMeth', filename, group, datasets, outgroup, outdataset, func, overwrite))
}

#' Crossprod with hdf5 matrix
#' 
#' This function performs the crossprod from a matrix inside and hdf5 data file
#' 
#' @param filename string file name where dataset to normalize is stored
#' @param group, string, group name where dataset A is stored
#' @param A string name inside HDF5 file
#' @param groupB, string, group name where dataset b is stored
#' @param B string, dataset name for matrix B inside HDF5 file
#' @param block_size (optional, defalut = 128) block size to make matrix multiplication, if `block_size = 1` no block size is applied (size 1 = 1 element per block)
#' @param paral, (optional, default = TRUE) if paral = TRUE performs parallel computation else performs seria computation
#' @param threads (optional) only if bparal = true, number of concurrent threads in parallelization if threads is null then threads =  maximum number of threads available
#' @param mixblock_size (optional) only for debug pourpose
#' @param outgroup (optional) group name to store results from Crossprod inside hdf5 data file
#' @return no value
#' @examples
#'   
#'   library(BigDataStatMeth)
#'   library(rhdf5)
#'   
#'   N = 1000
#'   M = 1000
#'   
#'   set.seed(555)
#'   a <- matrix( rnorm( N*M, mean=0, sd=1), N, M) 
#'   
#'   bdCreate_hdf5_matrix( filename = "test_temp.hdf5", 
#'                         object = a, group = "INPUT", 
#'                         dataset = "datasetA",
#'                         transp = FALSE,
#'                         overwriteFile = TRUE, 
#'                         overwriteDataset = FALSE, 
#'                         unlimited = FALSE)
#'                         
#'     file <- "test_temp.hdf5"
#'     dataset <- "results/res"
#'     
#'     bdCrossprod_hdf5( filename = "test_temp.hdf5", group = "INPUT", 
#'                        A = "datasetA", outgroup = "results", 
#'                        outdataset = "res", force = TRUE ) # 
#'                        
#'     # Check results
#'     resr <- tcrossprod(a)
#'     res <-  h5read(file,dataset)
#'     all.equal( resr, res)
#'     
#'     bdCrossprod_hdf5(filename = "test_temp.hdf5", group = "INPUT", 
#'                        A = "datasetA", outgroup = "results", 
#'                        outdataset = "res", block_size = 1024, 
#'                        force = TRUE ) # 
#'     
#'     # Check results
#'     resr <- tcrossprod(a)
#'     res <-  h5read(file,dataset)
#'     all.equal( resr, res)
#'   
#'     # Remove file (used as example)
#'     if (file.exists("test_temp.hdf5")) {
#'       file.remove("test_temp.hdf5")
#'     }
#'   
#' 
#' @export
bdCrossprod_hdf5 <- function(filename, group, A, B = NULL, groupB = NULL, block_size = NULL, mixblock_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, force = NULL) {
    invisible(.Call('_BigDataStatMeth_bdCrossprod_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, mixblock_size, paral, threads, outgroup, outdataset, force))
}

#' Normalize dataset in hdf5 file
#' 
#' This function normalize data scaling, centering or scaling and centering 
#' in a dataset stored in hdf5 file
#' 
#' @param filename string file name where dataset to normalize is stored
#' @param group string Matrix
#' @param dataset string Matrix
#' @param bcenter logical (default = TRUE) if TRUE, centering is done by 
#' subtracting the column means
#' @param bscale logical (default = TRUE) if TRUE, centering is done by 
#' subtracting the column means
#' @param byrows logical (default = FALSE) if TRUE, centering is done by 
#' subtracting the rows means, util when working with hdf5 datasets stored 
#' in Row Major format.
#' @param wsize integer (default = 1000), file block size to read to 
#' perform normalization
#' @param force, boolean if true, previous results in same location inside 
#' hdf5 will be overwritten.
#' @return file with scaled, centered or scaled and centered dataset
#' @examples
#'   a = "See vignette"
#' @export
bdNormalize_hdf5 <- function(filename, group, dataset, bcenter = NULL, bscale = NULL, byrows = NULL, wsize = NULL, force = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdNormalize_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, bcenter, bscale, byrows, wsize, force))
}

#' Hdf5 datasets multiplication
#'
#' Multiplies two existing datasets in hdf5 datafile and stores results i a new hdf5 dataset.
#' 
#' @export
bdblockmult_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, force = NULL) {
    invisible(.Call('_BigDataStatMeth_bdblockmult_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, paral, threads, outgroup, outdataset, force))
}

#' Block matrix multiplication
#' 
#' This function performs a block matrix-matrix multiplication with numeric matrix
#' 
#' @param filename string file name where dataset to normalize is stored
#' @param group string path inside hdf5 data file where matrix A is stored
#' @param A, string with dataset name where matrix is stored
#' @param B, string with dataset name where matrix is stored
#' @param groupB string path inside hdf5 data file where matrix B is stored
#' @param block_size integer, block size used to perform calculus
#' @param mixblock_size integer
#' @param outgroup string with the group name under the matrix will be stored
#' @param outdataset string with the dataset name to store results
#' @param force, boolean
#' 
#' @return list with filename and the group and dataset name under the results are stored
#' @examples
#' 
#' library(Matrix)
#' library(BigDataStatMeth)
#' 
#' k <- 1e3
#' set.seed(1)
#' x_sparse <- sparseMatrix(
#'     i = sample(x = k, size = k),
#'     j = sample(x = k, size = k),
#'     x = rnorm(n = k)
#' )
#' set.seed(2)
#' y_sparse <- sparseMatrix(
#'     i = sample(x = k, size = k),
#'     j = sample(x = k, size = k),
#'     x = rnorm(n = k)
#' )
#' 
#' if( isTRUE(file.exists('BasicMatVect.hdf5'))) {
#'      file.remove('BasicMatVect.hdf5')
#' }
#' bdCreate_hdf5_matrix("BasicMatVect.hdf5", as.matrix(x_sparse), "SPARSE", "x_sparse")
#' bdCreate_hdf5_matrix("BasicMatVect.hdf5", as.matrix(y_sparse), "SPARSE", "y_sparse")
#' 
#' d <- bdblockmult_sparse_hdf5("BasicMatVect.hdf5", "SPARSE", "x_sparse", "y_sparse")
#' 
#' # Remove file (used as example)
#' if (file.exists("BasicMatVect.hdf5")) {
#'   # Delete file if it exist
#'   file.remove("BasicMatVect.hdf5")
#' }
#' 
#' @export
bdblockmult_sparse_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, mixblock_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, force = NULL) {
    invisible(.Call('_BigDataStatMeth_bdblockmult_sparse_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, mixblock_size, paral, threads, outgroup, outdataset, force))
}

#' Hdf5 datasets substract
#'
#' Substracts two existing datasets in hdf5 datafile and stores results i a new hdf5 dataset.
#' 
#' @export
bdblockSubstract_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, force = NULL) {
    invisible(.Call('_BigDataStatMeth_bdblockSubstract_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, paral, threads, outgroup, outdataset, force))
}

#' Hdf5 datasets sum
#'
#' Sum two existing datasets in hdf5 datafile and stores results i a new hdf5 dataset.
#' 
#' @export
bdblockSum_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, force = NULL) {
    invisible(.Call('_BigDataStatMeth_bdblockSum_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, paral, threads, outgroup, outdataset, force))
}

#' tCrossprod with hdf5 matrix
#' 
#' This function performs the tcrossprod from a matrix inside and hdf5 data file
#' 
#' @param filename string file name where dataset to normalize is stored
#' @param group, string, group name where dataset A is stored
#' @param A string name inside HDF5 file
#' @param groupB, string, group name where dataset b is stored
#' @param B string, dataset name for matrix B inside HDF5 file
#' @param block_size (optional, defalut = 128) block size to make matrix multiplication, if `block_size = 1` no block size is applied (size 1 = 1 element per block)
#' @param paral, (optional, default = TRUE) if paral = TRUE performs parallel computation else performs seria computation
#' @param threads (optional) only if bparal = true, number of concurrent threads in parallelization if threads is null then threads =  maximum number of threads available
#' @param mixblock_size (optional) only for debug pourpose
#' @param outgroup (optional) group name to store results from tCrossprod inside hdf5 data file
#' @return no value
#' @examples
#'   
#'   library(BigDataStatMeth)
#'   library(rhdf5)
#'   
#'   N = 1000
#'   M = 1000
#'   
#'   set.seed(555)
#'   a <- matrix( rnorm( N*M, mean=0, sd=1), N, M) 
#'   
#'   bdCreate_hdf5_matrix( filename = "test_temp.hdf5", 
#'                         object = a, group = "INPUT", 
#'                         dataset = "datasetA",
#'                         transp = FALSE,
#'                         overwriteFile = TRUE, 
#'                         overwriteDataset = FALSE, 
#'                         unlimited = FALSE)
#'                         
#'     file <- "test_temp.hdf5"
#'     dataset <- "results/res"
#'     
#'     bdtCrossprod_hdf5( filename = "test_temp.hdf5", group = "INPUT", 
#'                        A = "datasetA", outgroup = "results", 
#'                        outdataset = "res", force = TRUE ) # 
#'                        
#'     # Check results
#'     resr <- tcrossprod(a)
#'     res <-  h5read(file,dataset)
#'     all.equal( resr, res)
#'     
#'     bdtCrossprod_hdf5(filename = "test_temp.hdf5", group = "INPUT", 
#'                        A = "datasetA", outgroup = "results", 
#'                        outdataset = "res", block_size = 1024, 
#'                        force = TRUE ) # 
#'     
#'     # Check results
#'     resr <- tcrossprod(a)
#'     res <-  h5read(file,dataset)
#'     all.equal( resr, res)
#'   
#'     # Remove file (used as example)
#'     if (file.exists("test_temp.hdf5")) {
#'       file.remove("test_temp.hdf5")
#'     }
#'   
#' 
#' @export
bdtCrossprod_hdf5 <- function(filename, group, A, B = NULL, groupB = NULL, block_size = NULL, mixblock_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, force = NULL) {
    invisible(.Call('_BigDataStatMeth_bdtCrossprod_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, mixblock_size, paral, threads, outgroup, outdataset, force))
}

#' Gets all dataset names inside a group
#'
#' Gets a list of all dataset names inside a group or all the datasets names 
#' starting with a prefix under a group
#' 
#' @param filename, character array with the name of the file to be accessed
#' @param group, character array with the input group name where the data sets are stored 
#' @param prefix, character array optional, indicates the prefix with which the dataset
#' names begin, if null, then the function returns all datasets inside the group
#' @return character array with the name of all datasets inside the group
#' @export
bdgetDatasetsList_hdf5 <- function(filename, group, prefix = NULL) {
    .Call('_BigDataStatMeth_bdgetDatasetsList_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, prefix)
}

#' Converts text file to hdf5 data file
#'
#' Converts text file to hdf5 data file
#'
#' @param filename string file name with data to be imported
#' @param outputfile file name and path to store imported data
#' @param outGroup group name to store the dataset
#' @param outDataset dataset name to store the input file in hdf5
#' @param sep (optional), by default = "\\t". The field separator string. Values within each row of x are separated by this string.
#' @param header (optional) either a logical value indicating whether the column names of x are to be written along with x, or a character vector of column names to be written. See the section on ‘CSV files’ for the meaning of col.names = NA.
#' @param rownames (optional) either a logical value indicating whether the row names of x are to be written along with x, or a character vector of row names to be written.
#' @param overwrite (optional) either a logical value indicating whether the output file can be overwritten or not.
#'
#' @return none value returned, data are stored in a dataset inside an hdf5 data file.
#' @export
bdImportTextFile_hdf5 <- function(filename, outputfile, outGroup, outDataset, sep = NULL, header = FALSE, rownames = FALSE, overwrite = FALSE, paral = NULL, threads = NULL) {
    invisible(.Call('_BigDataStatMeth_bdImportTextFile_hdf5', PACKAGE = 'BigDataStatMeth', filename, outputfile, outGroup, outDataset, sep, header, rownames, overwrite, paral, threads))
}

#' Impute SNPs in hdf5 omic dataset 
#'
#' Impute SNPs in hdf5 omic dataset 
#' 
#' @param filename, character array indicating the name of the file to create
#' @param group, character array indicating the input group where the data set to be imputed is. 
#' @param dataset, character array indicating the input dataset to be imputed
#' @param bycols, boolean by default = true, true indicates that the imputation will be done by columns, otherwise, the imputation will be done by rows
#' @param outgroup, optional character array indicating group where the data set will be saved after imputation if `outgroup` is NULL, output dataset is stored in the same input group. 
#' @param outdataset, optional character array indicating dataset to store the resulting data after imputation if `outdataset` is NULL, input dataset will be overwritten. 
#' @param overwrite, optional boolean if true, previous results in same location 
#' inside hdf5 will be overwritten, by default overwrite = false, data was not overwritten.
#' @return Original hdf5 data file with imputed data
#' @examples
#' print('see vignette')
#' @export
bdImputeSNPs_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, bycols = TRUE, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdImputeSNPs_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, bycols, overwrite))
}

#' Get diagonal matrix
#'
#' Gry diagonal matrix from an existing dataset inside hdf5
#'
#' @param filename, character array with the name of an existin hdf5 data file containing the dataset to be modified
#' @param group, character array indicating the input group where dataset is stored
#' @param dataset, character array indicating the input dataset name
#' @return Numeric vector with all diagonal elements from hdf5 dataset
#' @examples
#' 
#' library(BigDataStatMeth)
#' library(rhdf5)
#' 
#' X <- matrix(rnorm(100), 10, 10)
#' diag(X) <- 0.5
#' # Create hdf5 data file with  data (Y)
#' bdCreate_hdf5_matrix("test_file2.hdf5", X, "data", "X", 
#'                        overwriteFile = TRUE, 
#'                        overwriteDataset = FALSE, 
#'                        unlimited = FALSE)
#' # Update diagonal
#' diagonal <- bdgetDiagonal_hdf5("test_file.hdf5", "data", "X")
#' 
#' @export
bdgetDiagonal_hdf5 <- function(filename, group, dataset) {
    .Call('_BigDataStatMeth_bdgetDiagonal_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset)
}

#' Write diagonal matrix
#'
#' Write diagonal matrix to an existing dataset inside hdf5
#'
#' @param diagonal, numeric vector with diagonal elements to be written in existing dataset. 
#' @param filename, character array with the name of an existin hdf5 data file containing the dataset to be modified
#' @param group, character array indicating the input group where the data set to be modified. 
#' @param dataset, character array indicating the input dataset to be modified
#' @return Original hdf5 dataset with new diagonal elements
#' @examples
#' library(BigDataStatMeth)
#' library(rhdf5)
#' 
#' # Prepare data and functions
#' X <- matrix(rnorm(100), 10, 10)
#' diagonal <- c(1,2,3,4,5,6,7, 8, 9, 10)
#' 
#' # Create hdf5 data file with  data (Y)
#' bdCreate_hdf5_matrix("test_file.hdf5", X, "data", "X", 
#'                       overwriteFile = TRUE, 
#'                       overwriteDataset = FALSE, 
#'                       unlimited = FALSE)
#' 
#' # Update diagonal
#' bdWriteDiagonal_hdf5(diagonal, "test_file.hdf5", "data", "X")
#' 
#' @export
bdWriteDiagonal_hdf5 <- function(diagonal, filename, group, dataset) {
    invisible(.Call('_BigDataStatMeth_bdWriteDiagonal_hdf5', PACKAGE = 'BigDataStatMeth', diagonal, filename, group, dataset))
}

#' Get sd and Mean by Rows or Columns
#' 
#' This functions gets Standard Deviation (sd) or Mean by Rows or Columns and
#' store results in hdf5 dataset inside the file
#' 
#' @param filename string file name where dataset to normalize is stored
#' @param group string Matrix
#' @param dataset string Matrix
#' @param sd logical (default = TRUE) if TRUE, standard deviation is computed
#' @param mean logical (default = TRUE) if TRUE, mean is computed 
#' @param byrows logical (default = FALSE) if TRUE, sd and mean are computed
#' by columns, if byrows=TRUE then sd and mean are computed by Rows.
#' @param wsize integer (default = 1000), file block size to read to 
#' perform calculus exitexit
#' @param force, boolean if true, previous results in same location inside 
#' hdf5 will be overwritten.
#' @return hdf5 data file containing two new datasets, one for sd (if sd is 
#' requested) and another for the mean (if mean is requested). Results are
#' stored inside a folder mean_sd inside hdf5 data file with names: 
#' sd.\<dataset\>, mean.\<dataset\> respectively
#' @examples
#' 
#' library(BigDataStatMeth)
#'     
#' # Prepare data and functions
#' set.seed(123)
#' Y <- matrix(rnorm(100), 10, 10)
#' X <- matrix(rnorm(10), 10, 1)
#'     
#' # Create hdf5 data file with  data (Y)
#' bdCreate_hdf5_matrix("test.hdf5", Y, "data", "Y", 
#'                         overwriteFile = TRUE, 
#'                         overwriteDataset = FALSE, 
#'                         unlimited = FALSE)
#' bdCreate_hdf5_matrix( "test.hdf5", X, "data", "X", 
#'                        overwriteFile = FALSE, 
#'                        overwriteDataset = FALSE, 
#'                        unlimited = FALSE)
#' 
#' # Get mean and sd        
#' bdgetSDandMean_hdf5(filename = "test.hdf5", group = "data", dataset = "Y",
#'                     sd = TRUE, mean = TRUE,byrows = TRUE)
#'         
#' @export
bdgetSDandMean_hdf5 <- function(filename, group, dataset, sd = NULL, mean = NULL, byrows = NULL, wsize = NULL, force = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdgetSDandMean_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, sd, mean, byrows, wsize, force))
}

#' Pseudo-Inverse
#' 
#' Compute the pseudo-inverse of a singular matrix
#' 
#' @param X Singular matrix (m x n)
#' @return Pseudo-inverse matrix of A
#' @export
bdpseudoinv <- function(X, threads = NULL) {
    .Call('_BigDataStatMeth_bdpseudoinv', PACKAGE = 'BigDataStatMeth', X, threads)
}

#' Pseudo-Inverse
#' 
#' Compute the pseudo-inverse of a singular matrix in hdf5 data files
#' 
#' @param filename, character array with the name of an existin hdf5 data file containing the dataset
#' @param group, character array indicating the input group where the dataset is stored
#' @param dataset, character array indicating the input dataset that contains an m x n singular matrix
#' @param outgroup optional, character array with output group name where we want to 
#' store results if not provided then results are stored in the same group as original dataset
#' @param outdataset character array with output dataset name where we want to store results
#' @param overwrite, optional boolean if true, previous results in same location inside 
#' hdf5 will be overwritten, by default force = false, data was not overwritten.
#' @param threads optional parameter. Integer with numbers of threads to be used
#' @return Pseudo-inverse matrix of A
#' @export
bdpseudoinv_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, overwrite = NULL, threads = NULL) {
    invisible(.Call('_BigDataStatMeth_bdpseudoinv_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, overwrite, threads))
}

#' Reduce hdf5 dataset
#'
#' Reduce hdf5 datasets inside a group by rows or columns and store complete matrix inside the hdf5 data file.
#' 
#' @param filename, character array with the name of the file where datasets are stored
#' @param group, character array with the input group name where the data sets are stored 
#' @param reducefunction, single character with function to apply, can be '+' or  '-'
#' @param outgroup, optional character array with the group name where the dataset will be stored after reduction. If `outgroup` is NULL, the resulting dataset is stored in the same input group. 
#' @param outdataset, optional character with the dataset name for the resulting dataset after reduction if `outdataset` is NULL, then the input group name is used as outdataset name 
#' @param overwrite, boolean if true, previous results in same location inside hdf5 will be overwritten.
#' @param remove, boolean if true, removes original matrices, by default bremove = false.
#' @return Full matrix with results from reduction
#' @export
bdReduce_hdf5_dataset <- function(filename, group, reducefunction, outgroup = NULL, outdataset = NULL, overwrite = FALSE, remove = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdReduce_hdf5_dataset', PACKAGE = 'BigDataStatMeth', filename, group, reducefunction, outgroup, outdataset, overwrite, remove))
}

#' Remove element group or dataset from  hdf5 file
#'
#' Remove group or dataset from  hdf5 file
#' 
#' @param filename, character array indicating the name of the file to create
#' @param element string vector with one or multiple elements to be removed, 
#' each element in the string vectur must be a complete route to the element to be removed.
#' @return none
#' @export
#' 
#' @examples
#' 
#' matA <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15), nrow = 3, byrow = TRUE)
#' matB <- matrix(c(15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,3,4,5,2,6,2,3,4,
#'                    42, 23, 23, 423,1,2), nrow = 3, byrow = TRUE)
#'                    
#' bdCreate_hdf5_matrix("BasicMatVect.hdf5", matA, "INPUT", "matA")
#' bdCreate_hdf5_matrix("BasicMatVect.hdf5", matB, "INPUT", "matB")
#' 
#' bdRemove_hdf5_element("BasicMatVect.hdf5", c("INPUT/matA", "INPUT/matB"))
#' 
#' 
#' # Remove file (used as example)
#'   if (file.exists("BasicMatVect.hdf5")) {
#'     # Delete file if it exist
#'     file.remove("BasicMatVect.hdf5")
#'   }
#' 
bdRemove_hdf5_element <- function(filename, elements) {
    invisible(.Call('_BigDataStatMeth_bdRemove_hdf5_element', PACKAGE = 'BigDataStatMeth', filename, elements))
}

#' Remove SNPs in hdf5 omic dataset with low data
#'
#' Remove SNPs in hdf5 omic dataset with low data
#' 
#' @param filename, character array indicating the name of the file to create
#' @param group, character array indicating the input group where the data set to be imputed is. 
#' @param dataset, character array indicating the input dataset to be imputed
#' @param outgroup, character array indicating group where the data set will be 
#' saved after remove data with if `outgroup` is NULL, output dataset is stored 
#' in the same input group. 
#' @param outdataset, character array indicating dataset to store the resulting 
#' data after imputation if `outdataset` is NULL, input dataset will be overwritten. 
#' @param pcent, by default pcent = 0.5. Numeric indicating the percentage to be 
#' considered to remove SNPs, SNPS with percentage equal or higest will be removed from data
#' @param bycols, boolean by default = true, if true, indicates that SNPs are in 
#' cols, if SNPincols = false indicates that SNPs are in rows.
#' @param overwrite, optional boolean if true, previous results in same location 
#' inside hdf5 will be overwritten, by default overwrite = false, data was not overwritten.
#' @return Original hdf5 data file without cols/rows with low represented snps
#' @examples
#' print('see vignette')
#' @export
bdRemovelowdata_hdf5 <- function(filename, group, dataset, outgroup, outdataset, pcent, bycols, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdRemovelowdata_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, pcent, bycols, overwrite))
}

#' Remove SNPs in hdf5 omic dataset with low data
#'
#' Remove SNPs in hdf5 omic dataset with low data
#' 
#' @param filename, character array indicating the name of the file to create
#' @param group, character array indicating the input group where the data set to be imputed is. 
#' @param dataset, character array indicating the input dataset to be imputed
#' @param outgroup, character array indicating group where the data set will be saved after remove data with if `outgroup` is NULL, output dataset is stored in the same input group. 
#' @param outdataset, character array indicating dataset to store the resulting data after imputation if `outdataset` is NULL, input dataset will be overwritten. 
#' @param maf, by default maf = 0.05. Numeric indicating the percentage to be considered to remove SNPs, SNPS with higest MAF will be removed from data
#' @param bycols, boolean by default = true, if true, indicates that SNPs are in cols, if SNPincols = false indicates that SNPs are in rows.
#' @param blocksize, integer, block size dataset to read/write and calculate MAF, by default this operations is made in with 100 rows if byrows = true or 100 cols if byrows = false.
#' @param overwrite, optional boolean if true, previous results in same location 
#' inside hdf5 will be overwritten, by default overwrite = false, data was not overwritten.
#' @return Original hdf5 data file with imputed data
#' @export
bdRemoveMAF_hdf5 <- function(filename, group, dataset, outgroup, outdataset, maf, bycols, blocksize, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdRemoveMAF_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, maf, bycols, blocksize, overwrite))
}

#' Sort existing dataset 
#'
#' Sort an existing dataset taking in to account a list with sorted positions
#' 
#' @param filename, character array indicating the name of the file to be sorted
#' @param group, character array indicating the input group where the data set 
#' to be sorted is stored.
#' @param dataset, character array indicating the input dataset to be sorted
#' @param outdataset, character array indicating the name for the new sorted 
#' dataset. This dataset 
#' @param blockedSortlist, a list with blocks with sorted positions, see example
#' $`1`
#'                       chr order newOrder Diagonal
#' TCGA-OR-A5J1 TCGA-OR-A5J1     1        1        1
#' TCGA-OR-A5J2 TCGA-OR-A5J2     2        2        1
#' TCGA-OR-A5J3 TCGA-OR-A5J3     3        3        1
#' TCGA-OR-A5J4 TCGA-OR-A5J4     4        4        1
#' 
#' $`2`
#'                       chr order newOrder
#' TCGA-OR-A5J5 TCGA-OR-A5JA    10        5        1
#' TCGA-OR-A5J6 TCGA-OR-A5JB    11        6        1
#' TCGA-OR-A5J7 TCGA-OR-A5JC    12        7        0
#' TCGA-OR-A5J8 TCGA-OR-A5JD    13        8        1
#' 
#' $`3`
#'                       chr order newOrder
#' TCGA-OR-A5J9 TCGA-OR-A5J5     5        9        1
#' TCGA-OR-A5JA TCGA-OR-A5J6     6       10        1
#' TCGA-OR-A5JB TCGA-OR-A5J7     7       11        1
#' TCGA-OR-A5JC TCGA-OR-A5J8     8       12        1
#' TCGA-OR-A5JD TCGA-OR-A5J9     9       13        0
#' 
#' where rowname is the current rowname, chr is the new rowname, order is the
#' current position and newOrder is the new position
#' @param func, character array function to be applyed
#' \describe{
#'     \item{sortRows}{sort datasets rows}
#'     \item{sortCols}{sort datasets columns}
#' }
#' @param outgroup, optional, character array indicating group where the data 
#' set will be saved after imputation if `outgroup` is NULL, output dataset is 
#' stored in the same input group. 
#' @param overwrite, boolean if true, previous results in same location inside hdf5
#' will be overwritten.
#' @return Original hdf5 data file with sorted dataset
#' @examples
#' 
#' print("See vignette")
#' @export
bdSort_hdf5_dataset <- function(filename, group, dataset, outdataset, blockedSortlist, func, outgroup = NULL, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdSort_hdf5_dataset', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outdataset, blockedSortlist, func, outgroup, overwrite))
}

#' Split hdf5 dataset
#'
#' Split hdf5 dataset in small datasets by rows or columns and store splitted submatrices inside an hdf5 file.
#' 
#' @param filename, character array indicating the name of the file where dataset to split is stored
#' @param group, character array indicating the input group where the data set to be splitted is. 
#' @param dataset, character array indicating the input dataset to be splitted
#' @param outgroup, optional character array indicating group where the data set will be saved after split process if `outgroup` is NULL, output dataset is stored in the same input group. 
#' @param outdataset, optional character array indicating basename for the splitted dataset if `outdataset` is NULL, input dataset name is used adding .x, where x is the splitted block number. 
#' @param nblocks, integer number of blocks in which we want to split the data
#' @param blocksize, integer, number of elements in each block
#' @param bycols, boolean by default = true, true indicates that the imputation will be done by columns, otherwise, the imputation will be done by rows
#' @param force, boolean if true, previous results in same location inside hdf5 will be overwritten.
#' @return Splitted datasets inside an hdf5 data file
#' @export
bdSplit_matrix_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, nblocks = NULL, blocksize = NULL, bycols = TRUE, force = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdSplit_matrix_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, nblocks, blocksize, bycols, force))
}

#' Write Upper/Lower triangular matrix
#'
#' Write diagonal matrix to an existing dataset inside hdf5
#'
#' @param filename, character array with the name of an existin hdf5 data file containing the dataset to be modified
#' @param group, character array indicating the input group where the data set to be modified. 
#' @param dataset, character array indicating the input dataset to be modified
#' @param copytolower, boolean with default value = false. If true, sets lower 
#' triangular matrix using upper triangular matrix, if lower=false (default 
#' value) sets upper triangular matrix using lower triangular matrix.
#' @param elementsBlock, optional integer defines de maximum number of elements 
#' to read from hdf5 data file in each block. By default this value is set 
#' to 10000. If matrix is bigger thant 5000x5000 then block is set to number 
#' of rows or columns x 2
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Prepare data and functions
#' X <- matrix(rnorm(100), 10, 10)
#' X.1 <- X
#' X[lower.tri(X)] <- 0
#' # Create hdf5 data file with  data (Y)
#' bdCreate_hdf5_matrix("test_file.hdf5", X, "data", "X", 
#'                       overwriteFile = TRUE, 
#'                       overwriteDataset = FALSE, 
#'                       unlimited = FALSE)
#' # Update Lower triangular matrix in hdf5
#' bdWriteOppsiteTriangularMatrix_hdf5(filename = "test_file.hdf5", 
#'         group = "data", dataset = "X", copytolower = TRUE, elementsBlock = 10)
#' 
#' X <- X.1
#' X[upper.tri(X)] <- 0
#' # CAdd matrix data to a file
#' bdCreate_hdf5_matrix( "test_file.hdf5", X, "data", "Y", 
#'                         overwriteFile = FALSE, 
#'                         overwriteDataset = FALSE, 
#'                         unlimited = FALSE)
#' # Update Upper triangular matrix in hdf5
#' bdWriteOppsiteTriangularMatrix_hdf5(filename = "test_file.hdf5", 
#'         group = "data", dataset = "Y", copytolower = FALSE, elementsBlock = 10)
#' 
#' @export
bdWriteOppsiteTriangularMatrix_hdf5 <- function(filename, group, dataset, copytolower = NULL, elementsBlock = 1000000L) {
    invisible(.Call('_BigDataStatMeth_bdWriteOppsiteTriangularMatrix_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, copytolower, elementsBlock))
}

#' Apply vector calculus to a dataset in hdf5 file
#' 
#' This function applies a calculus with a vector to a matrix. Multiplies, 
#' sums, substract or divide each matrix row/column from a hdf5 dataset 
#' using a vector
#' 
#' @param filename string file name where dataset to apply weights is located
#' @param group string with the path inside the hdf5 data file where matrix 
#' is located
#' @param dataset string with the matrix name
#' @param vectorgroup string with the path inside the hdf5 data file where 
#' vector is located
#' @param vectordataset string with the vector name
#' @param outdataset character array with output dataset name where we want to 
#' store results
#' @param outgroup optional, character array with output group name where we 
#' want to store results if not provided then results are stored in the same 
#' group as original dataset
#' @param func, Character array, function to be applyed : 
#'"+" : to sum a vector to a matrix dataset by columns or rows
#'"-" : to substract a vector to a matrix dataset by columns or rows
#'"*" : to multiply a vector to a matrix dataset by columns or rows
#'"/" : to divide a vector to a matrix dataset by columns or rows
#' @param byrows logical (default = FALSE). By default weights are applied by 
#' columns but if byrows=TRUE then weights are applied by rows 
#' @param paral, (optional, default = TRUE) if paral = TRUE performs parallel 
#' computation else performs seria computation
#' @param threads (optional) only if bparal = true, number of concurrent 
#' threads in parallelization if threads is null then threads =  maximum 
#' number of threads available
#' @param force, boolean if true, previous results in same location inside 
#' hdf5 will be overwritten.
#' @return file with weighted dataset
#' @examples
#'library(BigDataStatMeth)
#'    
#'# Prepare data and functions
#'set.seed(123)
#'Y <- matrix(rnorm(100), 10, 10)
#'X <- matrix(rnorm(10), 10, 1)
#'        
#'# Create hdf5 data file with  data (Y)
#'bdCreate_hdf5_matrix("test.hdf5", Y, "data", "Y", overwriteFile = TRUE, 
#'                         overwriteDataset = FALSE, 
#'                         unlimited = FALSE)
#'bdCreate_hdf5_matrix("test.hdf5",  X, "data", "X", overwriteFile = FALSE, 
#'                         overwriteDataset = FALSE, 
#'                         unlimited = FALSE)
#'            
#'bdcomputeMatrixVector_hdf5("test.hdf5", 
#'                           group = "data", dataset = "Y",
#'                           vectorgroup = "data", vectordataset = "X", 
#'                           outdataset = "ProdComputed", 
#'                           func = "*",
#'                           byrows = TRUE, force = TRUE)
#'    
#'bdcomputeMatrixVector_hdf5("test.hdf5", 
#'                           group = "data", dataset = "Y",
#'                           vectorgroup = "data", vectordataset = "X", 
#'                           outdataset = "SumComputed", 
#'                           func = "-",
#'                           byrows = TRUE, force = TRUE)
#'    
#'bdcomputeMatrixVector_hdf5("test.hdf5", 
#'                           group = "data", dataset = "Y",
#'                           vectorgroup = "data", vectordataset = "X", 
#'                           outdataset = "SubsComputed", 
#'                           func = "-",
#'                           byrows = FALSE, force = TRUE)
#' @export
bdcomputeMatrixVector_hdf5 <- function(filename, group, dataset, vectorgroup, vectordataset, outdataset, func, outgroup = NULL, byrows = NULL, paral = NULL, threads = NULL, force = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdcomputeMatrixVector_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, vectorgroup, vectordataset, outdataset, func, outgroup, byrows, paral, threads, force))
}

#' @title Matrix multiplication
#' @description Miltiplies two existing data matrices on memory
#' @param A Matrix A
#' @param B Matrix B
#' @param block_size Block size to be used to perform computation, if null the maximum block size allowed is used . Default: NULL, 
#' @param paral if paral = TRUE performs parallel computation else performs seria computation, Default: FALSE
#' @param byBlocks If data matrix has more than 2.25e+08 (15000 x 15000) elements, by default the addition is done by blocks, but it can be forced not to be partitioned with parameter byblocks = FALSE, Default: TRUE
#' @param threads only if bparal = true, number of concurrent threads in parallelization if threads is null then threads =  (maximum number of threads available / 2), Default: NULL
#' @return new matrix with A * B
#' @examples 
#' \dontrun{
#' if(interactive()){
#'     N <- 2500
#'     M <- 400
#'     nc <-  4
#'     
#'     set.seed(555)
#'     mat <- matrix( rnorm( N*M, mean=0, sd=10), N, M) 
#'     
#'     sum_mem = bdblockMult(mat, mat, paral = TRUE, threads = nc)
#'  }
#' }
#' @rdname bdblockSum
#' @export 
bdblockMult <- function(A, B, block_size = NULL, paral = NULL, byBlocks = TRUE, threads = NULL) {
    .Call('_BigDataStatMeth_bdblockMult', PACKAGE = 'BigDataStatMeth', A, B, block_size, paral, byBlocks, threads)
}

#' @title Hdf5 datasets substract
#' @description substract two existing datasets in hdf5 datafile and stores results i a new hdf5 dataset
#' @param A Matrix or vector A
#' @param B Matrix or vector B
#' @param block_size PARAM_DESCRIPTION, Default: NULL
#' @param paral if paral = TRUE performs parallel computation else performs seria computation, Default: FALSE
#' @param byBlocks If data matrix has more than 2.25e+08 (15000 x 15000) elements, by default the addition is done by blocks, but it can be forced not to be partitioned with parameter byblocks = FALSE, Default: TRUE
#' @param threads only if bparal = true, number of concurrent threads in parallelization if threads is null then threads =  (maximum number of threads available / 2), Default: NULL
#' @return new matrix with A + B
#' @examples 
#' \dontrun{
#' if(interactive()){
#'     N <- 2500
#'     M <- 400
#'     nc <-  4
#'     
#'     set.seed(555)
#'     mat <- matrix( rnorm( N*M, mean=0, sd=10), N, M) 
#'     
#'     sum_mem = bdblockSubstract(mat, mat, paral = TRUE, threads = nc)
#'  }
#' }
#' @rdname bdblockSubstract
#' @export 
bdblockSubstract <- function(A, B, block_size = NULL, paral = NULL, byBlocks = TRUE, threads = NULL) {
    .Call('_BigDataStatMeth_bdblockSubstract', PACKAGE = 'BigDataStatMeth', A, B, block_size, paral, byBlocks, threads)
}

#' @title Hdf5 datasets sum
#' @description Sum two existing datasets in hdf5 datafile and stores results i a new hdf5 dataset
#' @param A Matrix A
#' @param B Matrix B
#' @param block_size PARAM_DESCRIPTION, Default: NULL
#' @param paral if paral = TRUE performs parallel computation else performs seria computation, Default: FALSE
#' @param byBlocks If data matrix has more than 2.25e+08 (15000 x 15000) elements, by default the addition is done by blocks, but it can be forced not to be partitioned with parameter byblocks = FALSE, Default: TRUE
#' @param threads only if bparal = true, number of concurrent threads in parallelization if threads is null then threads =  (maximum number of threads available / 2), Default: NULL
#' @return new matrix with A + B
#' @examples 
#' \dontrun{
#' if(interactive()){
#'     N <- 2500
#'     M <- 400
#'     nc <-  4
#'     
#'     set.seed(555)
#'     mat <- matrix( rnorm( N*M, mean=0, sd=10), N, M) 
#'     
#'     sum_mem = bdblockSum(mat, mat, paral = TRUE, threads = nc)
#'  }
#' }
#' @rdname bdblockSum
#' @export 
bdblockSum <- function(A, B, block_size = NULL, paral = NULL, byBlocks = TRUE, threads = NULL) {
    .Call('_BigDataStatMeth_bdblockSum', PACKAGE = 'BigDataStatMeth', A, B, block_size, paral, byBlocks, threads)
}

#' Crossproduct 
#' 
#' This function performs a crossproduct of a numerical matrix.
#' 
#' @export
#' 
#' @param A numerical matrix
#' @param B optional, numerical matrix
#' @param transposed optional parameter. Boolean if true we use the 
#' transposed dataframe to perform calculus. By default transp_dataset = false. 
#' @param block_size (optional, defalut = NULL) block size to make matrix 
#' multiplication, if `block_size = 1` no block size is applied 
#' (size 1 = 1 element per block) if `block_size = NULL` (default) optimum 
#' block size is computed
#' @param paral, (optional, default = TRUE) if paral = TRUE performs parallel 
#' computation else if paral = FALSE performs serial computation
#' @param threads (optional) only if bparal = true, number of concurrent threads
#' in parallelization if threads is null then threads =  maximum number of 
#' threads available
#' @return numerical matrix with crossproduct
#' @examples
#' 
#' n <- 100
#' p <- 60
#' 
#' X <- matrix(rnorm(n*p), nrow=n, ncol=p)
#' res <- bdCrossprod(X)
#' 
#' all.equal(crossprod(X), res)
#' 
#' n <- 100
#' p <- 100
#' 
#' Y <- matrix(rnorm(n*p), nrow=n)
#' 
#' # With two matrices
#' res <- bdCrossprod(X,Y)
#' 
#' @export
bdCrossprod <- function(A, B = NULL, transposed = NULL, block_size = NULL, paral = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdCrossprod', PACKAGE = 'BigDataStatMeth', A, B, transposed, block_size, paral, threads)
}

#' Transpodsed Crossproduct 
#' 
#' This function performs a transposed crossproduct of a numerical matrix.
#' 
#' @export
#' 
#' @param A numerical matrix
#' @param B optional, numerical matrix
#' @param block_size (optional, defalut = NULL) block size to make matrix 
#' multiplication, if `block_size = 1` no block size is applied 
#' (size 1 = 1 element per block) if `block_size = NULL` (default) optimum 
#' block size is computed
#' @param paral, (optional, default = TRUE) if paral = TRUE performs parallel 
#' computation else if paral = FALSE performs serial computation
#' @param threads (optional) only if bparal = true, number of concurrent threads
#' in parallelization if threads is null then threads =  maximum number of 
#' threads available
#' @return numerical matrix with transposed crossproduct
#' @examples
#' 
#' n <- 100
#' p <- 60
#' 
#' X <- matrix(rnorm(n*p), nrow=n, ncol=p)
#' res <- bdtCrossprod(X)
#' 
#' all.equal(tcrossprod(X), res)
#' 
#' n <- 100
#' p <- 100
#' 
#' Y <- matrix(rnorm(n*p), nrow=n)
#' 
#' # With two matrices
#' res <- bdtCrossprod(X,Y)
#' 
#' @export
bdtCrossprod <- function(A, B = NULL, transposed = NULL, block_size = NULL, paral = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdtCrossprod', PACKAGE = 'BigDataStatMeth', A, B, transposed, block_size, paral, threads)
}

#' Create hdf5 data file and write data to it
#'
#' Creates a hdf5 file with numerical data matrix,
#' 
#' @param filename, character array indicating the name of the file to create
#' @param object numerical data matrix
#' @param group, character array indicating folder name to put the matrix in hdf5 file
#' @param dataset, character array indicating the dataset name to store the matix data
#' @param transp boolean, if trans=true matrix is stored transposed in hdf5 file
#' @param overwriteFile, optional boolean by default overwriteFile = false, if true and file exists, removes old file and creates a new file with de dataset data.
#' @param overwriteDataset, optional boolean by default overwriteDataset = false,  if true and dataset exists, removes old dataset and creates a new dataset.
#' @param unlimited, optional boolean by default unlimited = false, if true creates a dataset that can growth.
#' @return none
#' 
#' @examples
#' 
#' matA <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15), nrow = 3, byrow = TRUE)
#' bdCreate_hdf5_matrix(filename = "test_temp.hdf5", 
#'                     object = matA, group = "datasets", 
#'                     dataset = "datasetA", transp = FALSE, 
#'                     overwriteFile = TRUE, 
#'                     overwriteDataset = TRUE,
#'                     unlimited = FALSE)
#' 
#' # Remove file (used as example)
#'   if (file.exists("test_temp.hdf5")) {
#'     # Delete file if it exist
#'     file.remove("test_temp.hdf5")
#'   }
#' 
#' @export
bdCreate_hdf5_matrix <- function(filename, object, group = NULL, dataset = NULL, transp = NULL, overwriteFile = NULL, overwriteDataset = NULL, unlimited = NULL) {
    invisible(.Call('_BigDataStatMeth_bdCreate_hdf5_matrix', PACKAGE = 'BigDataStatMeth', filename, object, group, dataset, transp, overwriteFile, overwriteDataset, unlimited))
}

